## HW6 - Знакомство с Terraform

Создание директории terraform внутри проекта infra. Внутри директории terraform создан главный конфигурационный файл, что содержит декларативное описание инфраструктуры: main.tf.

Чтобы не коммитить в репозиторий служебные файлы и директории создан файл .gitignore.

Определены следующие секции в файле main.tf:

- Provider - позволит Terraform управлять ресурсами GCP через API вызовы

- resource - добавлен ресурс для создания инстанса VM в GCP

- boot_disk - в определении загрузочного диска для VM, передаем имя семейства образа(base-образ)

- allow - открыт порт для приложения

- source_ranges - каким адресам разрешен доступ

- target_tags - для каких  инстансов применимо правило с перечисленными тэгами

- tags - добавлен тег в определении ресурса

- provisioner - вызываются в момент создания/удаления ресурса и позволяют выполнять команды на удаленной или локальной машине. 
                 Их используют для запуска инструментов управления конфигурацией или начальной настройки системы.


Планирование изменения и просмотр, что terraform собирается изменить относительно известного предыдущего состояния:

$terraform plan

Применение:

$terraform apply

Apply complete! Resources: 1 added, 0 changed, 0 destroyed

Результатом выполнения команды также будет создание файла terraform.tfstate в директории terraform. Terraform хранит в этом файле 
состояние управляемых им ресурсов.

Добавлен SSH ключ для пользователя appuser, с помощью метаданных инстанса через определение в main.tf внутри описание инстанса.

Обьявление vars:

- выходная переменная (output variable) - в отдельном файле outputs.tf

- входные переменные (input vars) - чтобы использовать входную переменную ее нужно сначала определить в отдельном файле variables.tf

- определение переменных используя специальный файл terraform.tfvars, из которого тераформ загружает значения автоматически при каждом  запуске

Отформатировать все конфигурационные файлы:

$terraform fmt


## HW7 -  Принципы организации инфраструктурного кода и работа над инфраструктурой в команде на примере Terraform 

Создание директории terraform-2 внутри проекта infra.

Определить ресурс файервола, импортировать существующую инфраструктуру в Terraform.

Задать IP для инстанса с приложением в виде внешнего ресурса. Проанализировать неявную зависимость.

Структурировать ресурсы для нескольких ВМ:

- вынести БД на отдельный инстанс VM

- в качестве базового образа для создания образа ubuntu16.04

- скопировать и подкорректировать уже имеющийся шаблон ubuntu16.json

- создать две VM, разбив конфиг main.tf на несколько конфигов app и db

- объявить переменные в variables.tf

- создать файл vpc.tf, в который будеь вынесено правило фаервола для ssh доступа

- внутри директории terraform создать директорию modules, в которой будут определены модули

- внутри директории modules создать директорию db, в которой создать три привычных файла main.tf, variables.tf,
outputs.tf

- скопировать содержимое db.tf в modules/db/main.tf

- определить переменные,которые используются в db.tf и объявляются в variables.tf в файл переменных модуля
modules/db/variables.tf

- создать по аналогии модуль приложения app

- удалить db.tf и app.tf в директории terraform, чтобы terraform перестал их использовать

- в файл main.tf, где определен провайдер, вставить секции вызова созданных модулей

- использовать команду для загрузки модулей: terraform get

- аналогично предыдущим модулям создать модуль vpc, в котором определить настройки файервола в рамках сети

- сделать параметризацию модулей за счет использования input переменных 

- задать диапазоны IP адресов для правила файервола при вызове модуля

- Проверьте работу параметризованного модуля vpc:

  - ввести в source_ranges не мой IP адрес, применить правило и проверить отсутствие соединения к обоим хостам по ssh

  Проконтролировать, как изменилось правило файрвола в вебконсоли

  - ввести в source_ranges мой IP адрес, применить правило и проверить наличие соединения к обоим хостам по ssh

  - вернуть 0.0.0.0/0 в source_ranges

- переиспользование модулей: 

  - создать инфраструктуру для двух окружений (stage и prod), используя созданные модули

  - в директории terrafrom создайте две директории stage и prod

  - скопировать файлы main.tf, variables.tf, outputs.tf, terraform.tfvars из директории terraform в каждую из
  созданных директорий

  - поменять пути к модулям в main.tf на ../modules/xxx вместо modules/xxx

  - открыть SSH доступ для всех IP адресов в окружении Stage, а в окружении Prod открыть доступ только для своего IP

  - удалить из папки terraform файлы main.tf, outputs.tf, terraform.tfvars, variables.tf, так как они теперь перенесены
  в stage и prod

  - параметризировать конфигурацию модулей по своему усмотрению

  - отформатировать конфигурационные файлы, используя команду terraform fmt

- воспользоваться модулем для создания бакета в сервисе Storage:

  - создать в папке terraform файл storage-bucket.tf, использу модуль storage-bucket

  - создать или скопировать готовые variables.tf и terraform.tfvars для проекта и региона

  - применить конфигурацию тераформа

## HW8 - Написание Ansible плейбуков на основе имеющихся bash скриптов

Создание директории ansible внутри проекта infra.

- установка Ansible:

  - создать в директории ansible файл requirements.txt

  - пакетным менеджером установить ansible: pip install -r requirements.txt

  - проверить установку ansible: ansible --version

- знакомство с базовыми функциями и инвентори:

  - для управление инстансом при помощи Ansible убедиться, что возможно подключиние к нему по SSH

  - хосты и группы хостов, которыми Ansible должен управлять, описать в инвентори-файле

  - указать значения по умолчанию для работы Ansible в ansible.cfg

  - использовать YAML для inventory

- выполнение различных модулей на подготовленной в прошлых ДЗ инфраструктуре:

  - убедиться, что Ansible может управлять хостом, используя команду ansible для вызова модуля ping из командной строки

  - использовать модуль command, который позволяет запускать произвольные команды на удаленном хосте

  - проверить на хосте с БД статус сервиса MongoDB с помощью модуля command или shell

  - выполнить ту же операцию используя модуль systemd, который предназначен для управления сервисами

  - так же ипользовать модуль service, который более универсален и будет работать и в более старых ОС с init.d инициализацией

  - использовать модуль git для клонирования репозитория с приложением на app сервер

- написать простой плейбук, который выполняет клонирование репозитория:

  - создать файл ansible/clone.yml

  - выполнить ansible app -m command -a 'rm -rf ~/reddit' и проверьте еще раз выполнение плейбука

Т. к. был удален репозиторий reddit, то после повторного выполнения плейбука, видим что репозиторий reddit снова будет добавлен.

## HW9 - Продолжение знакомства с Ansible: templates, handlers, dynamic inventory, vault, tags

Использование директории ansible внутри проекта infra.

- использование плейбука, хендлеров и шаблонов для конфигурации окружения и деплоя тестового приложения

- реализовать подходы:

  - один плейбук, один сценарий (play)

  - один плейбук, но много сценариев

  - много плейбуков

- изменить провижн образов Packer на Ansible-плейбуки

